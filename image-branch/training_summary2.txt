训练配置详情：
- 模型架构: MobileNetV3 Small (mnv3_small)
- 输入图像尺寸: 192×192
- 训练轮数 (epochs): 40
- 批大小 (batch size): 32
- 数据集分割: split1
- 类别数量: 23（MINC-2500）

预训练权重：
- 来源: PyTorch 官方 MobileNetV3 Small (ImageNet)
- 下载路径: C:\Users\lenovo\.cache\torch\hub\checkpoints\mobilenet_v3_small-047dcff4.pth

每个 Epoch 的验证指标（Loss / Val Acc / Val F1 / Time）：
Epoch	Loss	Val Acc	Val F1	Time(s)
1	1.6311	0.7089	0.7062	171.7
2	1.3573	0.7395	0.7339	133.5
3	1.2643	0.7412	0.7391	122.1
4	1.2020	0.7548	0.7523	119.3
5	1.1490	0.7569	0.7525	119.4
6	1.1035	0.7256	0.7227	118.9
7	1.0624	0.7513	0.7499	119.3
8	1.0311	0.7402	0.7419	119.1
9	0.9952	0.7388	0.7360	119.6
10	0.9662	0.7478	0.7481	131.8
11	0.9412	0.7579	0.7546	121.1
12	0.9192	0.7461	0.7455	120.1
13	0.8966	0.7513	0.7490	120.0
14	0.8777	0.7468	0.7459	120.0
15	0.8600	0.7475	0.7479	120.0
16	0.8450	0.7353	0.7336	119.7
17	0.8299	0.7485	0.7479	119.2
18	0.8132	0.7485	0.7467	119.6
19	0.8008	0.7558	0.7535	119.1
20	0.7869	0.7513	0.7496	120.1
21	0.7758	0.7558	0.7540	120.3
22	0.7653	0.7656	0.7635	120.4
23	0.7562	0.7558	0.7546	119.9
24	0.7437	0.7572	0.7555	120.6
25	0.7375	0.7572	0.7542	120.0
26	0.7281	0.7631	0.7615	119.7
27	0.7210	0.7642	0.7628	120.5
28	0.7132	0.7617	0.7595	119.9
29	0.7075	0.7635	0.7614	119.9
30	0.7015	0.7677	0.7663	120.0
31	0.6951	0.7673	0.7653	121.1
32	0.6939	0.7711	0.7697	120.5
33	0.6899	0.7711	0.7694	119.9
34	0.6862	0.7715	0.7699	120.0
35	0.6823	0.7704	0.7684	120.3
36	0.6802	0.7722	0.7702	120.5
37	0.6796	0.7725	0.7705	120.1
38	0.6775	0.7708	0.7684	121.0
39	0.6768	0.7722	0.7703	120.0
40	0.6766	0.7715	0.7693	120.1

训练输出目录：
- out_dir: F:\study\LSMRT\image-branch\runs\mnv3_small_s192_split1_resize
- 最佳模型路径: F:\study\LSMRT\image-branch\runs\mnv3_small_s192_split1_resize\best.pt

最终测试性能（使用 best.pt）：
- 测试准确率 (test_acc): 0.7690  （≈76.90%）
- 宏平均F1分数 (macro_f1): 0.7676 （≈76.76%）




训练配置详情：
- 模型架构: MobileNetV3 Large (mnv3_large)
- 输入图像尺寸: 192×192
- 训练轮数 (epochs): 40
- 批大小 (batch size): 16
- 数据集分割: split1
- 强数据增强: 启用 (--strong_aug)  rrc0.6
- 类别数量: 23（MINC-2500）


每个 Epoch 的验证指标（Loss / Val Acc / Val F1 / Time）：
Epoch	Loss	Val Acc	Val F1	Time(s)
1	1.5312	0.7148	0.7118	180.4
2	1.3320	0.7527	0.7534	149.7
3	1.2589	0.7506	0.7469	150.4
4	1.2126	0.7649	0.7602	156.7
5	1.1775	0.7642	0.7643	149.7
6	1.1522	0.7690	0.7676	149.9
7	1.1244	0.7534	0.7542	149.8
8	1.1054	0.7638	0.7609	150.4
9	1.0862	0.7478	0.7471	149.7
10	1.0690	0.7534	0.7510	150.2
11	1.0495	0.7430	0.7414	150.0
12	1.0341	0.7513	0.7491	150.0
13	1.0200	0.7663	0.7629	150.1
14	1.0046	0.7590	0.7600	150.3
15	0.9903	0.7426	0.7403	150.0
16	0.9679	0.7576	0.7567	150.3
17	0.9520	0.7527	0.7505	150.2
18	0.9344	0.7416	0.7454	150.4
19	0.9163	0.7461	0.7430	150.8
20	0.8980	0.7527	0.7511	151.6
21	0.8761	0.7489	0.7473	150.4
22	0.8570	0.7513	0.7526	150.1
23	0.8420	0.7558	0.7543	158.0
24	0.8241	0.7586	0.7573	152.1
25	0.8101	0.7544	0.7537	150.4
26	0.7907	0.7628	0.7622	155.2
27	0.7758	0.7659	0.7653	157.8
28	0.7619	0.7590	0.7580	164.8
29	0.7462	0.7621	0.7601	183.0
30	0.7359	0.7694	0.7692	170.3
31	0.7254	0.7617	0.7624	174.1
32	0.7128	0.7670	0.7665	166.4
33	0.7059	0.7635	0.7626	162.3
34	0.6985	0.7708	0.7708	165.9
35	0.6921	0.7628	0.7622	161.2
36	0.6860	0.7704	0.7698	161.9
37	0.6835	0.7697	0.7690	162.7
38	0.6803	0.7683	0.7673	168.2
39	0.6783	0.7666	0.7658	164.7
40	0.6766	0.7656	0.7648	167.1

训练输出目录：
- out_dir: F:\study\LSMRT\image-branch\runs\mnv3_large_s192_split1_rrc
- 最佳模型路径: F:\study\LSMRT\image-branch\runs\mnv3_large_s192_split1_rrc\best.pt

最终测试性能（使用 best.pt）：
- 测试准确率 (test_acc): 0.7831 （≈78.31%）
- 宏平均F1分数 (macro_f1): 0.7840 （≈78.40%）

备注：
- 使用了强数据增强 (--strong_aug)，有助于提高模型泛化能力。
- 相较于 MobileNetV3 Small 版本，Large 版本在相同分辨率下表现更优（约高 1.4% 准确率和 F1 分数）。
- 训练时间较长，特别是后期 epoch 耗时增加（如第 29 轮耗时 183 秒），可能是由于学习率降低导致收敛速度减慢。

- test_acc: 0.7831304347826087
- test_macro_f1: 0.7839785581993324
- confusion_matrix shape: (23, 23)

img_size: 192
images: 512
total_sec: 0.7427802085876465
ms_per_img: 1.450742594897747




训练配置详情：
- 模型架构: MobileNetV3 Large (mnv3_large)
- 输入图像尺寸: 192×192
- 训练轮数 (epochs): 40
- 批大小 (batch size): 16
- 数据集分割: split1
- 强数据增强: 启用 (--strong_aug)
- 随机裁剪比例下限 (--rrc_scale_low): 0.75
- 类别数量: 23（MINC-2500）

每个 Epoch 的验证指标（Loss / Val Acc / Val F1 / Time）：

Epoch	Loss	Val Acc	Val F1	Time(s)
1	1.5026	0.7290	0.7228	196.6
2	1.2870	0.7600	0.7600	168.5
3	1.2102	0.7447	0.7438	162.5
4	1.1623	0.7659	0.7592	166.2
5	1.1234	0.7802	0.7790	162.5
6	1.0911	0.7739	0.7757	162.1
7	1.0673	0.7715	0.7731	162.5
8	1.0436	0.7687	0.7654	163.1
9	1.0205	0.7708	0.7706	162.2
10	1.0068	0.7739	0.7733	162.3
11	0.9897	0.7809	0.7799	161.9
12	0.9707	0.7562	0.7534	162.7
13	0.9573	0.7489	0.7471	163.8
14	0.9390	0.7496	0.7509	163.0
15	0.9242	0.7579	0.7580	163.2
16	0.9052	0.7656	0.7635	163.1
17	0.8876	0.7683	0.7693	163.9
18	0.8727	0.7656	0.7656	163.0
19	0.8562	0.7527	0.7502	164.1
20	0.8401	0.7635	0.7643	164.0
21	0.8260	0.7666	0.7659	164.6
22	0.8059	0.7631	0.7631	163.5
23	0.7888	0.7659	0.7639	164.4
24	0.7770	0.7586	0.7599	176.1
25	0.7608	0.7656	0.7659	164.5
26	0.7508	0.7704	0.7706	166.3
27	0.7300	0.7694	0.7691	164.0
28	0.7210	0.7718	0.7710	164.9
29	0.7089	0.7767	0.7760	167.9
30	0.7026	0.7736	0.7736	165.6
31	0.6905	0.7757	0.7752	164.4
32	0.6816	0.7784	0.7776	164.9
33	0.6766	0.7819	0.7819	164.1
34	0.6677	0.7826	0.7827	165.8
35	0.6648	0.7812	0.7806	165.9
36	0.6596	0.7812	0.7807	164.3
37	0.6580	0.7861	0.7860	164.8
38	0.6568	0.7861	0.7856	165.4
39	0.6540	0.7875	0.7870	164.8
40	0.6530	0.7882	0.7877	165.2

训练输出目录：
- out_dir: F:\study\LSMRT\image-branch\runs\mnv3_large_s192_split1_rrc0.75
- 最佳模型路径: F:\study\LSMRT\image-branch\runs\mnv3_large_s192_split1_rrc0.75\best.pt

最终测试性能（使用 best.pt）：
- 测试准确率 (test_acc): 0.8003 （≈80.03%）
- 宏平均F1分数 (macro_f1): 0.8002 （≈80.02%）

备注：
- 使用了强数据增强 (--strong_aug) 和随机裁剪比例下限 (--rrc_scale_low 0.75)，有助于提高模型泛化能力。
- 相较于之前的实验（--rrc_scale_low 0.8），在相同的分辨率和模型架构下，此配置下的测试准确率和F1分数略有下降，分别降低了约 0.58% 和 0.56%。
- 训练时间较为稳定，每轮耗时大致在 162 到 176 秒之间。


test_acc: 0.800695652173913
test_macro_f1: 0.800526897694392
confusion_matrix shape: (23, 23)

img_size: 192
images: 512
total_sec: 0.7852716445922852
ms_per_img: 1.533733680844307





训练配置详情：
- 模型架构: MobileNetV3 Large (mnv3_large)
- 输入图像尺寸: 192×192
- 训练轮数 (epochs): 40
- 批大小 (batch size): 16
- 数据集分割: split1
- 强数据增强: 启用 (--strong_aug)
- 随机裁剪比例下限 (--rrc_scale_low): 0.8
- 类别数量: 23（MINC-2500）

每个 Epoch 的验证指标（Loss / Val Acc / Val F1 / Time）：

Epoch	Loss	Val Acc	Val F1	Time(s)
1	1.4909	0.7412	0.7366	186.6
2	1.2700	0.7739	0.7736	159.0
3	1.1935	0.7708	0.7674	162.1
4	1.1433	0.7663	0.7609	162.0
5	1.1009	0.7659	0.7671	163.9
6	1.0738	0.7680	0.7673	163.9
7	1.0446	0.7781	0.7795	163.8
8	1.0189	0.7718	0.7694	164.1
9	1.0003	0.7683	0.7670	164.7
10	0.9846	0.7739	0.7732	165.0
11	0.9670	0.7757	0.7748	164.3
12	0.9476	0.7621	0.7611	164.5
13	0.9354	0.7666	0.7636	164.8
14	0.9207	0.7736	0.7736	164.9
15	0.9011	0.7725	0.7719	164.4
16	0.8843	0.7715	0.7709	164.5
17	0.8710	0.7694	0.7676	165.1
18	0.8525	0.7597	0.7587	164.5
19	0.8358	0.7809	0.7779	164.8
20	0.8202	0.7725	0.7732	164.7
21	0.7995	0.7701	0.7680	165.0
22	0.7838	0.7816	0.7806	164.1
23	0.7728	0.7732	0.7718	164.4
24	0.7591	0.7746	0.7751	164.7
25	0.7419	0.7777	0.7771	164.9
26	0.7312	0.7892	0.7880	165.0
27	0.7152	0.7656	0.7650	164.4
28	0.7082	0.7871	0.7854	164.9
29	0.6934	0.7857	0.7847	164.9
30	0.6874	0.7830	0.7821	166.0
31	0.6767	0.7899	0.7897	165.7
32	0.6694	0.7941	0.7940	165.1
33	0.6648	0.7955	0.7946	165.3
34	0.6586	0.7934	0.7935	167.7
35	0.6538	0.7965	0.7958	173.0
36	0.6509	0.7993	0.7986	174.8
37	0.6474	0.7965	0.7958	174.7
38	0.6471	0.7969	0.7962	173.7
39	0.6450	0.7986	0.7982	173.6
40	0.6437	0.8017	0.8011	174.0

训练输出目录：
- out_dir: F:\study\LSMRT\image-branch\runs\mnv3_large_s192_split1_rrc0.8
- 最佳模型路径: F:\study\LSMRT\image-branch\runs\mnv3_large_s192_split1_rrc0.8\best.pt

最终测试性能（使用 best.pt）：
- 测试准确率 (test_acc): 0.8061 （≈80.61%）
- 宏平均F1分数 (macro_f1): 0.8058 （≈80.58%）

备注：
- 使用了强数据增强 (--strong_aug) 和随机裁剪比例下限 (--rrc_scale_low 0.8)，有助于提高模型泛化能力。
- 相较于之前的实验（未指定 --rrc_scale_low），在相同的分辨率和模型架构下，此配置进一步提升了测试准确率和F1分数，分别提高了约 2.3% 和 2.18%。
- 训练时间较为稳定，每轮耗时大致在 164 到 175 秒之间。

test_acc: 0.8060869565217391
test_macro_f1: 0.8057548006722915
confusion_matrix shape: (23, 23)

images: 512
total_sec: 0.8002755641937256
ms_per_img: 1.5630382113158703






训练配置详情：
- 模型架构: EfficientNet-B0 (effb0)
- 输入图像尺寸: 192×192
- 训练轮数 (epochs): 40
- 批大小 (batch size): 16
- 数据集分割: split1
- 强数据增强: 未启用（仅默认增强）
- 随机裁剪比例下限 (--rrc_scale_low): 默认（未指定，通常为 0.08）
- 类别数量: 23（MINC-2500）

每个 Epoch 的验证指标（Loss / Val Acc / Val F1 / Time）：

Epoch	Loss	Val Acc	Val F1	Time(s)
1	1.5242	0.7770	0.7752	242.3
2	1.2680	0.7917	0.7901	216.1
3	1.1802	0.7920	0.7895	217.5
4	1.1209	0.8052	0.8039	217.5
5	1.0705	0.7979	0.7970	240.1
6	1.0371	0.7896	0.7886	212.6
7	1.0069	0.7843	0.7821	211.4
8	0.9772	0.7944	0.7922	212.4
9	0.9605	0.7843	0.7830	211.9
10	0.9390	0.7958	0.7951	210.9
11	0.9208	0.7920	0.7905	211.0
12	0.9046	0.7889	0.7867	210.8
13	0.8872	0.7979	0.7957	210.8
14	0.8682	0.7861	0.7850	210.7
15	0.8581	0.7923	0.7920	211.7
16	0.8391	0.7882	0.7881	210.8
17	0.8295	0.7923	0.7907	210.4
18	0.8158	0.7885	0.7882	211.5
19	0.7985	0.7781	0.7784	211.8
20	0.7847	0.7830	0.7792	210.3
21	0.7732	0.7906	0.7898	210.8
22	0.7574	0.7962	0.7948	210.4
23	0.7438	0.7899	0.7885	210.9
24	0.7329	0.7965	0.7957	210.4
25	0.7198	0.7930	0.7926	210.1
26	0.7104	0.7941	0.7937	210.5
27	0.6961	0.8021	0.8024	209.9
28	0.6892	0.7983	0.7975	210.6
29	0.6793	0.7972	0.7956	210.8
30	0.6716	0.8090	0.8085	211.8
31	0.6646	0.8000	0.7993	213.6
32	0.6601	0.8038	0.8030	211.3
33	0.6549	0.8073	0.8064	224.9
34	0.6490	0.8049	0.8047	232.6
35	0.6465	0.8083	0.8070	211.1
36	0.6447	0.8070	0.8049	212.2
37	0.6420	0.8115	0.8110	211.8
38	0.6405	0.8118	0.8113	214.2
39	0.6393	0.8094	0.8088	211.7
40	0.6388	0.8115	0.8107	212.0

训练输出目录：
- out_dir: F:\study\LSMRT\image-branch\runs\effb0_s192_split1_resize
- 最佳模型路径: F:\study\LSMRT\image-branch\runs\effb0_s192_split1_resize\best.pt

最终测试性能（使用 best.pt）：
- 测试准确率 (test_acc): 0.8237 （≈82.37%）
- 宏平均F1分数 (macro_f1): 0.8233 （≈82.33%）

备注：
- 使用了预训练的 EfficientNet-B0（从 rwightman 权重加载），输入尺寸 192×192。
- 未启用 --strong_aug，因此仅使用默认的数据增强策略（如随机水平翻转、标准 Resize 等）。
- 尽管没有强增强，该模型在 MINC-2500 上表现优于之前所有 MobileNetV3 Large 实验（包括 rrc=0.8 和 rrc=0.75 的设置）。
- 最终测试准确率比 mnv3_large + rrc=0.8（80.61%）高出约 1.76%，表明 EfficientNet-B0 在此任务中具有更强的表征能力。
- 训练时间较长（每 epoch ≈210–240 秒），约为 MobileNetV3 的 1.3 倍，符合其更大计算量的特点。

=== Benchmark Result ===
ckpt: F:\study\LSMRT\image-branch\runs\effb0_s192_split1_resize\best.pt
arch: effb0
img_size: 192
images: 512
total_sec: 6.427875280380249
ms_per_img: 12.554443906992674




训练配置详情：
- 模型架构: EfficientNet-B0 (effb0)
- 输入图像尺寸: 224×224
- 训练轮数 (epochs): 20
- 批大小 (batch size): 32
- 初始学习率 (lr): 3e-4
- 数据集分割: split1
- 数据增强: 默认（未启用 --strong_aug）
- 类别数量: 23（MINC-2500）
- 工作进程数 (num_workers): 8
- GPU: CUDA_VISIBLE_DEVICES=0

数据路径：
- 训练集列表: /root/mqx/LSMRT/data/minc-2500/labels/train1.txt
- 验证集列表: /root/mqx/LSMRT/data/minc-2500/labels/validate1.txt
- 测试集列表: /root/mqx/LSMRT/data/minc-2500/labels/test1.txt

每个 Epoch 的验证指标（Loss / Val Acc / Val F1 / Time）：

Epoch	Loss	Val Acc	Val F1	Time(s)
1	1.4193	0.8080	0.8058	592.8
2	1.1419	0.8136	0.8127	560.1
3	1.0426	0.8191	0.8180	567.8
4	0.9744	0.8296	0.8292	582.2
5	0.9175	0.8282	0.8281	593.9
6	0.8731	0.8226	0.8213	584.2
7	0.8332	0.8355	0.8343	593.0
8	0.7988	0.8306	0.8293	606.8
9	0.7737	0.8330	0.8322	572.7
10	0.7455	0.8264	0.8260	589.0
11	0.7240	0.8379	0.8373	577.0
12	0.7080	0.8400	0.8396	614.5
13	0.6908	0.8438	0.8424	591.9
14	0.6796	0.8428	0.8419	611.8
15	0.6715	0.8438	0.8431	592.7
16	0.6617	0.8393	0.8388	588.8
17	0.6557	0.8435	0.8429	603.7
18	0.6517	0.8459	0.8449	558.2
19	0.6496	0.8466	0.8454	481.5
20	0.6477	0.8497	0.8490	478.2

训练输出目录：
- out_dir: /root/mqx/LSMRT/image-branch/runs/effb0_s224_split1_resize
- 最佳模型路径: /root/mqx/LSMRT/image-branch/runs/effb0_s224_split1_resize/best.pt

最终测试性能（使用 best.pt）：
- 测试准确率 (test_acc): 0.8567 （≈85.67%）
- 宏平均F1分数 (macro_f1): 0.8562 （≈85.62%）

推理速度基准测试（bench_speed_cli.py）：
- 测试图像数量: 2000 张
- 总耗时: 122.30 秒
- 单图推理时间: 61.15 毫秒/图
- 等效吞吐量: ≈16.32 图像/秒

备注：
- 相较于之前 192×192 输入尺寸的 EfficientNet-B0 实验（test_acc ≈82.37%），提升输入分辨率至 224×224 显著提高了性能（+3.3% 准确率）。
- 尽管 batch size 增大至 32，训练时间每 epoch 仍控制在 8–10 分钟，后期因 GPU 利用率优化，单 epoch 时间缩短至约 8 分钟。
- 推理速度实测为 61.15 ms/图，在普通服务器 GPU（如 RTX 3090/4090 或 A100）上属于合理范围，兼顾精度与效率。
- 该配置（effb0 + 224 + lr=3e-4）是目前所有实验中性能最佳的方案。




